{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1: Identificando números con imágenes\n",
    "En este ejercicio analizaras e identificarás números dados en la forma de imagen. Para ello puedes utilizar tu solución preferida identificar grupos de imágenes similares. Por ejemplo, puedes aplicar reducción de dimensionalidad antes o después del entrenamiento, puedes también elegir no usarlo. Para hacer la predicción puedes hacer uso de un método de agrupamiento y resolver la tarea con aprendizaje no supervisado, o puedes utilizar un algoritmo de clasificación y elegir el camino de aprendizaje supervisado.\n",
    "\n",
    "A diferencia de los ejercicios anteriores donde programaste las soluciones analíticas a los métodos de ML, en este proyecto se recomienda el uso de las funciones y clases integradas de scikit-learn. Para entender el uso de estas clases y ver algunos ejemplos puedes consultar la documentación oficial [sk-learn user guide](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "En este proyecto tendrás que elegir que método de reducción de dimensionalidad y que método de agrupamiento deseas aplicar a tus datos. Es tu trabajo analizar la información dada para tomar estas decisiones. Lee con atención todas las instrucciones y celdas de código, y recuerda agregar tu código en todas las partes donde veas la instrucción \"`TODO`\"\n",
    "\n",
    "## Descripción\n",
    "Tu trabajo es identificar grupos en imágenes para reconocimiento de números. Para esto, deberás realizar los siguientes pasos:\n",
    "1. Dado que nuestros datos están en diferentes escalas, es necesario normalizar los datos.\n",
    "2. Aplicar un método de reducción de dimensionalidad y visualizar los datos\n",
    "3. Buscar grupos en los datos reducidos con alguna técnica de agrupamiento o clasificación.\n",
    "4. Interpretar los resultados.\n",
    "5. Dadas dos imágenes nuevas, identificar a que grupo pertenece. (Inferencia)\n",
    "\n",
    "Nota como existen múltiples soluciones a este problema. La decisión de como resolverlo es tuya (: intenta hacerlo lo mejor posible!\n",
    "Comenzamos por importar las librerías correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Analizando los datos\n",
    " Comenzamos leyendo nuestros datos y visualizando algunos ejemplos para analizarlos. En este caso utilizaremos el [digits dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html#sphx-glr-auto-examples-datasets-plot-digits-last-image-py). En este dataset encontrarás 1797 imágenes de 8x8. Cada imagen es un dígito escrito a mano. Primero separaremos los datos en entrenamiento y validación\n",
    "\n",
    " Recuerda! los datos de entranmiento *son los únicos* que puedes usar para entrenar tus modelos. El conjunto de validación solo se utilizará para evaluar el rendimiento de los modelos que elijas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos nuestros datos y los separamos en entrenamiento y validación\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "data_train, data_val, target_train, target_val = train_test_split(\n",
    "    data, \n",
    "    labels, \n",
    "    test_size=0.25\n",
    ")\n",
    "print(f\"Imágenes en rango {np.max(data)}, {np.min(data)}\")\n",
    "\n",
    "# Entrenamiento\n",
    "(n_samples, n_features), n_digits = data_train.shape, np.unique(target_train).size\n",
    "print(f\"# Dígitos: {n_digits}; # Muestras de entrenamiento: {n_samples}; # Variables {n_features}\")\n",
    "\n",
    "# Validación\n",
    "(n_samples, n_features), n_digits = data_val.shape, np.unique(target_val).size\n",
    "print(f\"# Dígitos: {n_digits}; # Muestras de validación: {n_samples}; # Variables {n_features}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio las imágenes se entregan como un vector de 64 variables, donde cada elemento corresponde al valor de un pixel. Para visualizar los datos en forma de imagen, es necesario transformarlos a la forma adecuada. En las siguiente celda puedes ver algunas imágenes de ejemplo, así como la forma en que podemos transformar el vector de variables a una matriz de 8x8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "\n",
    "# Visualizar algunas imágenes\n",
    "n_cols = 3\n",
    "idx = np.random.randint(len(data_train), size=n_cols)\n",
    "fig, axes = plt.subplots(1, n_cols, figsize=(6,3))\n",
    "axes = axes.flatten()\n",
    "for ax, i in zip(axes, idx):\n",
    "    side = np.sqrt(len(data_train[i])).astype('int')\n",
    "    # La imagen está dada como un solo vector de longitud 64\n",
    "    # Cambiamos la forma para tenerla en forma de imagen de 8x8 pixeles\n",
    "    img = data[i].reshape((side, side))\n",
    "    ax.matshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Etiqueta: {labels[i]}\")\n",
    "fig.suptitle(\"Ejemplos de muestras de entrenamiento\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización en baja dimensionalidad\n",
    "En la siguiente celda puedes visualizar como se ven tus datos reduciendo la dimensionalidad de 30 variables a 2. Explora usar TSNE y PCA, y elige el que te de mejor información.\n",
    "\n",
    "Utiliza las siguientes preguntas para analizar la imgen:\n",
    "- ¿Cual método de reducción de dimensionalidad funciona mejor en este caso?\n",
    "- ¿Que puedes deducir de esta imagen?\n",
    "- ¿Qué representa cada color en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "# TODO Reducimos la dimensionalidad de los datos de validacion data_val\n",
    "# a 2 dimensiones usando TSNE y/o PCA\n",
    "reduced_data = ...\n",
    "\n",
    "labels = np.unique(target_train)\n",
    "fig, ax_pca = plt.subplots(1, 1, figsize=(4,4))\n",
    "fig.suptitle(\"Puntos reducidos a dos dimensiones\")\n",
    "for c in labels:\n",
    "    indices = np.where(target_train == c)\n",
    "    plot_data = reduced_data[indices]\n",
    "    ax_pca.scatter(plot_data[:, 0], plot_data[:, 1], label=f\"Grupo {c}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tu turno - Entrenamiento\n",
    "Utiliza los datos `data_train` con las etiquetas `target_train` define para entrenar un modelo que identifique dígitos. \n",
    "Utiliza las librerías de sklearn para entrenar al menos dos modelos. En esta sección queda a tu criterio:\n",
    "- Decidir si entrenarás en alta o baja dimensionalidad\n",
    "- Decidir los modelos que deseas comparar (k-means, reg.logistica, naive bayes, random trees etc.)\n",
    "- Decidir qué tipo de procesamiento (si alguno) deseas aplicar y por qué\n",
    "\n",
    "Puedes consultar todos los modelos disponibles de sklear en el [user-guide](https://scikit-learn.org/stable/supervised_learning.html). \n",
    "\n",
    "Un método de preprocesamiento de datos muy comun, es normalizar las entradas antes de entrenar el modelo. Considera que si decides hacer esto, deberás normalizar también los datos de validación durante inferencia **DE LA MISMA MANERA** en que normalizaste los datos de entrenamiento. Se recomienda ampliamente el uso de StandardScale para este objetivo.\n",
    "\n",
    "Considera que **en todo momento** los datos de validación no se usan para encontrar ningún parámetro. Tienes que asumir que no existen hasta el momento que quieras predecir datos usando los modelos que hayas estimado con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa las clases que necesites para entrenar los modelos de sklearn\n",
    "\n",
    "# Entontramos los valores de normalización USANDO LOS DATOS DE ENTRENAMIENTO\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_train)\n",
    "\n",
    "def train(X, label, model_type:str):\n",
    "    # Normalizamos los datos de entrenamiento\n",
    "    data = scaler.transform(X)\n",
    "\n",
    "    # TODO: Entrena el modelo y regresa el modelo entrenado en los datos de entrenamiento\n",
    "    # model puede ser tanto la instancia de la clase que quieras usar, como un string indicando\n",
    "    if model_type == \"algun_modelo\":\n",
    "        estimator = ...\n",
    "    elif model_type == \"otra_cosa\":\n",
    "        estimator = ...\n",
    "    else:\n",
    "        estimator = ...\n",
    "\n",
    "    return estimator\n",
    "\n",
    "def inference(trained_model, X_val):\n",
    "    # En inferencia, podemos recibir un solo dato entonces X_val.shape seria (D, )\n",
    "    # Las clases de sklearn siempre esperan todo en la forma de  N, D\n",
    "    if X_val.ndim == 1:\n",
    "        X_val = X_val.reshape(1, -1)\n",
    "\n",
    "    # TODO: Normaliza los datos de validación\n",
    "    # El mismos preprocesamiento de datos se aplica a\n",
    "    # tanto inferencia como entrenamiento\n",
    "    data = ...\n",
    "\n",
    "    # TODO: Utiliza el modelo para predecir valores para los datos de validación\n",
    "    # Regresa las predicciones de tu modelo para X_val\n",
    "    # En este caso, modelo tiene que ser una instancia de una clase para la cual quieres hacer predicción\n",
    "\n",
    "    return preds\n",
    "\n",
    "trained_models = {\n",
    "    \"algun_modelo\": None,\n",
    "    \"otra_cosa\": None,\n",
    "    ...\n",
    "}\n",
    "for model_type in trained_models.keys():\n",
    "    modelo = train(data_train, target_train, model_type=model_type)\n",
    "    trained_models[model_type] = modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluación y análisis de las predicciones\n",
    "En esta sección incluimos funciones que te permiten visualizar la predicción de tu modelo para el set de validación. Dado que nuestros datos son de alta dimensionalidad (64) necesitamos reducirlos para poder analizar las predicciones. Recuerda que en esta sección solo funcionará si has definido tu modelo correctamente en el método anterior `mi_modelo`.\n",
    "\n",
    "## 3.1 (Inferencia) Datos de validación en baja dimensionalidad\n",
    "Completa el código de la siguiente celda para visualizar **las predicciones de TU modelo** de el conjunto de validación en baja dimensionalidad. Utiliza el método de reducción de dimensionalidad que consideres te ayude mejor a analizar tus datos. Cada clase/grupo deberá mostrarse en un color diferente. En base a lo que puedes observar en la imagen, ¿consideras que tu algoritmo ha aprendido algo que tiene sentido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_low_dim(data_val, preds, model_type):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "    fig.suptitle(f\"Puntos clasificados {model_type} (2 dimensiones)\")\n",
    "\n",
    "    # Buscamos la cantidad de grupos que hay en los datos de validación\n",
    "    groups = np.unique(preds)\n",
    "    n_groups = len(groups)\n",
    "    # Graficamos los datos, con un color diferente para cada clase/grupo\n",
    "    print(f\"Datos {data_val.shape}, predicciones {preds.shape}, clases/grupos {n_groups}\")\n",
    "\n",
    "    # TODO: Reduce los datos de VALIDACIÓN data_val a dos dimensiones para poder visualizarlos\n",
    "    reduced_data = ...\n",
    "    for g in groups:\n",
    "        # TODO: Grafica los datos de VALIDACIÓN reducidos (reduced_data.shape = (N, 2))\n",
    "        # Tal que grafiques aquellos que correspondan al grupo/clase group\n",
    "        # Investiga plt.scatter, np.where o cómo filtrar arreglos dada una condición booleana\n",
    "        ...\n",
    "    fig.show()\n",
    "    fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = trained_models[\"logistic_reg\"]\n",
    "# Llamamos a inferencia de tu modelo\n",
    "for model_type, modelo in trained_models.items():\n",
    "    preds = inference(modelo, data_val)\n",
    "    vis_low_dim(data_val, preds, model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza la imagen anterior e intenta explicar lo que esta motstrando.\n",
    "- ¿Que representa cada color en la imagen?\n",
    "- Dada la imagen, ¿Parece que el modelo entrenado ha aprendido algo con sentido? Explica tu razonamiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 (Inferencia) Visualizar imagenes en cada grupo/clase\n",
    "Completa el código de la siguiente celda. El siguiente código llama al método de inferencia anteriormente definido. Deberás mostrar 1 imagen por cada grupo de predicción de tu modelo, intenta seleccionar una imagen representativa del grupo tal que puedas ver que es lo que ha aprendido tu modelo.\n",
    "\n",
    "#### Métodos de clasificación\n",
    "Si utilizaste un método de clasificación multiclase, los esperable sería que el valor real de la muestra (GT) sea igual al valor de la predicción para al menos la mayoría de los casos.\n",
    "\n",
    "#### Métodos de agrupamiento\n",
    "Si utilizaste un algoritmo de agrupamiento, es esperable que el valor real de la muestra (GT) no sea igual al grupo de tu predicción. Recuerda que al ser aprendizaje no supervisado, necesitamos adicionalmente \"mapear\" los grupos que haya encontrado el algoritmo a los reales. Puedes usar esta sección para hacer dicho mapeo. Lo mas sencillo es usar un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_preds(trained_model, data_val, target_val, model_name):\n",
    "    # Llamamos a inferencia de su modelo\n",
    "    # Este método regresará una cantidad definida de clases\n",
    "    # Que haya encontrado para los datos de validación\n",
    "    preds = inference(modelo, data_val)\n",
    "    group_pred = np.unique(preds)\n",
    "    n_groups = len(group_pred)\n",
    "\n",
    "    # Graficar\n",
    "    n_cols = 5\n",
    "    fig, axes = plt.subplots(n_groups//n_cols, n_cols, figsize=(10,6))\n",
    "    axes = axes.flatten()\n",
    "    for group, ax in zip(group_pred, axes):\n",
    "        #======================= Start  solution=====================\n",
    "        # TODO: Filtra data_val para quedarte solamente con aquellos elementos\n",
    "        # donde la predicción de tu modelo sea igual a group\n",
    "        # Haz lo mismo para las etiquetas\n",
    "\n",
    "\n",
    "        # TODO: Selecciona una imagen de los datos en data_val donde pred == group\n",
    "        # y selecciona la etiqueta real para dicha imagén para mostrarlos juntos\n",
    "        # Investiga: np.random.randint, np.random.choice etc.\n",
    "        gt = ...\n",
    "        img_vector = ...\n",
    "\n",
    "        # TODO: Calcula la predicción del modelo para la imagen aleatoria\n",
    "        # usando el modelo entrenado \"trained_model\"\n",
    "        pred = ...\n",
    "\n",
    "        # TODO: La predicción del modelo usa la imagen en forma de vector (1xD)\n",
    "        # pero para visualizarla tenemos que cambia de forma a una imagen de 8x8 pixeles\n",
    "        # Cambia la forma de la imagen usando np.reshape a (8, 8)\n",
    "        img = ...\n",
    "        \n",
    "        # TODO: Visualiza la imagen de 8x8 usando ax.matshow Similar al inicio del ejercicio\n",
    "        # Revisa la documentación de ser necesario\n",
    "        \n",
    "\n",
    "        #======================= end  solution=====================\n",
    "        ax.set_title(f\"Pred:{pred}, GT: {gt}\")\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(f\"Muestras por grupo({model_name})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for name, trained_model in trained_models.items():\n",
    "    vis_preds(trained_model, data_val, target_val, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 (Inferencia) Comparar rendimento de distintos modelos\n",
    "En esta sección evalúa tus dos modelos entrenados en el conjunto de validación utilizando alguna métrica vista en clase (accuracy, F1, Precision, Recall etc.) y determina cuantitativamente cual funciona mejor. Investiga como usar las métricas de sklearn en la sección de [Classification metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# TODO: Para todos los modelos que entrenaste, calcula un valor \n",
    "# que indique la calidad de las predicciones en los datos de validación\n",
    "# utiliza: data_val y target_val\n",
    "for name, trained_model in trained_models.items():\n",
    "    # Calcula la predicción y evalúa la calidad de predicción vs. las etiquetas reales (target_val)\n",
    "    print(f\"Modelo {name}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base al análisis tanto cualitativo como cuantitativo, discute en tu blog cual modelo funciona mejor justificando tu razonamiento. Puedes usar las siguientes preguntas como guía según las decisiones que hayas tomado:\n",
    "- ¿Funcionó mejor entrenar en alta o baja dimensionalidad?\n",
    "- ¿Funcionó mejor usar un método de aprendizaje supervisado o no supervisado?\n",
    "- ¿Probaste algún método de preprocesamiento distinto?\n",
    "- ¿Funcionó mejor usar imágenes normalizadas o no normalizadas?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistemas_inteligentes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04dc998fdd71cb65825f35fa039c285a87c761883882ab18ec8c9090ce63cd9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
